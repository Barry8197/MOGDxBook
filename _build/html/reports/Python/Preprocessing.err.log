Traceback (most recent call last):
  File "/Users/barryryan/anaconda3/lib/python3.11/site-packages/jupyter_cache/executors/utils.py", line 58, in single_nb_execution
    executenb(
  File "/Users/barryryan/anaconda3/lib/python3.11/site-packages/nbclient/client.py", line 1204, in execute
    return NotebookClient(nb=nb, resources=resources, km=km, **kwargs).execute()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/barryryan/anaconda3/lib/python3.11/site-packages/nbclient/util.py", line 84, in wrapped
    return just_run(coro(*args, **kwargs))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/barryryan/anaconda3/lib/python3.11/site-packages/nbclient/util.py", line 62, in just_run
    return loop.run_until_complete(coro)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/barryryan/anaconda3/lib/python3.11/asyncio/base_events.py", line 653, in run_until_complete
    return future.result()
           ^^^^^^^^^^^^^^^
  File "/Users/barryryan/anaconda3/lib/python3.11/site-packages/nbclient/client.py", line 663, in async_execute
    await self.async_execute_cell(
  File "/Users/barryryan/anaconda3/lib/python3.11/site-packages/nbclient/client.py", line 965, in async_execute_cell
    await self._check_raise_for_error(cell, cell_index, exec_reply)
  File "/Users/barryryan/anaconda3/lib/python3.11/site-packages/nbclient/client.py", line 862, in _check_raise_for_error
    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)
nbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:
------------------
## Perform Feature Selection Pipeline

data_to_save = {}
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
#device = 'cpu'

### Check if the index of the count matrix and the metadata match
if len(set(count_mtx.index) & set(datMeta.index)) == 0 : 
    count_mtx = count_mtx.T

### Perform Feature Selection for the specified pipeline
if pipeline == 'DESeq' :
    print('Performing Differential Gene Expression for Feature Selection')
    datMeta.index.name = 'index'

    ### Preprocess the data
    count_mtx , datMeta = preprocess_functions.data_preprocess(count_mtx.astype(int).astype(np.float32), datMeta[target]  , gene_exp = False)

    ### Perform DESeq
    dds, vsd, top_genes = preprocess_functions.DESEQ(count_mtx , datMeta , target , n_genes=500)

    ### Save the data
    data_to_save[f'extracted_feats'] = list(set(top_genes))
    datExpr = pd.DataFrame(data=vsd , index=count_mtx.index , columns=count_mtx.columns)
    
elif pipeline == 'LogReg' : 
    print('Performing Logistic Regression for Feature Selection')
    
    ### Preprocess the data
    n_genes = count_mtx.shape[1]
    datExpr = count_mtx.loc[: , (count_mtx != 0).any(axis=0)] # remove any genes with all 0 expression
    
    ### Perform Elastic Net
    extracted_feats , model , penalty = preprocess_functions.elastic_net(datExpr , datMeta[target] , n_feats=175, l1_ratio = 0.3)
    
    ### Save the data
    data_to_save['extracted_feats'] = list(set(extracted_feats))
    data_to_save['model'] = {'model' : model , 'penalty' : penalty}
    
    datMeta.index.name = 'index'
    datMeta = datMeta[target]
    
data_to_save['datExpr'] = datExpr
data_to_save['datMeta'] = datMeta

### Save the data
with open(f'./../../data/raw/{modality}_processed.pkl' , 'wb') as file : 
    pickle.dump(data_to_save , file)
    
------------------

[0;31m---------------------------------------------------------------------------[0m
[0;31mAssertionError[0m                            Traceback (most recent call last)
Cell [0;32mIn[4], line 34[0m
[1;32m     31[0m datExpr [38;5;241m=[39m count_mtx[38;5;241m.[39mloc[: , (count_mtx [38;5;241m!=[39m [38;5;241m0[39m)[38;5;241m.[39many(axis[38;5;241m=[39m[38;5;241m0[39m)] [38;5;66;03m# remove any genes with all 0 expression[39;00m
[1;32m     33[0m [38;5;66;03m### Perform Elastic Net[39;00m
[0;32m---> 34[0m extracted_feats , model , penalty [38;5;241m=[39m preprocess_functions[38;5;241m.[39melastic_net(datExpr , datMeta[target] , n_feats[38;5;241m=[39m[38;5;241m175[39m, l1_ratio [38;5;241m=[39m [38;5;241m0.3[39m)
[1;32m     36[0m [38;5;66;03m### Save the data[39;00m
[1;32m     37[0m data_to_save[[38;5;124m'[39m[38;5;124mextracted_feats[39m[38;5;124m'[39m] [38;5;241m=[39m [38;5;28mlist[39m([38;5;28mset[39m(extracted_feats))

File [0;32m~/Library/CloudStorage/OneDrive-UniversityofEdinburgh/PhD_Research/Year3/MOGDx/MOGDxBook/mogdx-book/Python/./../MAIN/preprocess_functions.py:112[0m, in [0;36melastic_net[0;34m(count_mtx, datMeta, n_feats, train_index, val_index, l1_ratio, num_epochs, device)[0m
[1;32m     95[0m [38;5;250m[39m[38;5;124;03m"""[39;00m
[1;32m     96[0m [38;5;124;03mApplies the Elastic Net algorithm for feature selection and model training.[39;00m
[1;32m     97[0m 
[0;32m   (...)[0m
[1;32m    109[0m [38;5;124;03m    tuple: A tuple containing the extracted features, the trained model, and the Elastic Net penalty.[39;00m
[1;32m    110[0m [38;5;124;03m"""[39;00m
[1;32m    111[0m [38;5;66;03m# Initialize your model and the ElasticNet regularization term[39;00m
[0;32m--> 112[0m model [38;5;241m=[39m ElasticNetModel(input_dim[38;5;241m=[39mcount_mtx[38;5;241m.[39mshape[[38;5;241m1[39m] , output_dim[38;5;241m=[39m[38;5;241m5[39m)[38;5;241m.[39mto(device)
[1;32m    113[0m penalty [38;5;241m=[39m ElasticNetPenalty(alpha[38;5;241m=[39m[38;5;241m0.05[39m, l1_ratio[38;5;241m=[39ml1_ratio)[38;5;241m.[39mto(device)
[1;32m    115[0m [38;5;66;03m# Define your loss function with ElasticNet regularization[39;00m

File [0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1160[0m, in [0;36mModule.to[0;34m(self, *args, **kwargs)[0m
[1;32m   1156[0m         [38;5;28;01mreturn[39;00m t[38;5;241m.[39mto(device, dtype [38;5;28;01mif[39;00m t[38;5;241m.[39mis_floating_point() [38;5;129;01mor[39;00m t[38;5;241m.[39mis_complex() [38;5;28;01melse[39;00m [38;5;28;01mNone[39;00m,
[1;32m   1157[0m                     non_blocking, memory_format[38;5;241m=[39mconvert_to_format)
[1;32m   1158[0m     [38;5;28;01mreturn[39;00m t[38;5;241m.[39mto(device, dtype [38;5;28;01mif[39;00m t[38;5;241m.[39mis_floating_point() [38;5;129;01mor[39;00m t[38;5;241m.[39mis_complex() [38;5;28;01melse[39;00m [38;5;28;01mNone[39;00m, non_blocking)
[0;32m-> 1160[0m [38;5;28;01mreturn[39;00m [38;5;28mself[39m[38;5;241m.[39m_apply(convert)

File [0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:810[0m, in [0;36mModule._apply[0;34m(self, fn, recurse)[0m
[1;32m    808[0m [38;5;28;01mif[39;00m recurse:
[1;32m    809[0m     [38;5;28;01mfor[39;00m module [38;5;129;01min[39;00m [38;5;28mself[39m[38;5;241m.[39mchildren():
[0;32m--> 810[0m         module[38;5;241m.[39m_apply(fn)
[1;32m    812[0m [38;5;28;01mdef[39;00m [38;5;21mcompute_should_use_set_data[39m(tensor, tensor_applied):
[1;32m    813[0m     [38;5;28;01mif[39;00m torch[38;5;241m.[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):
[1;32m    814[0m         [38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,[39;00m
[1;32m    815[0m         [38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,[39;00m
[0;32m   (...)[0m
[1;32m    820[0m         [38;5;66;03m# global flag to let the user control whether they want the future[39;00m
[1;32m    821[0m         [38;5;66;03m# behavior of overwriting the existing tensor or not.[39;00m

File [0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:810[0m, in [0;36mModule._apply[0;34m(self, fn, recurse)[0m
[1;32m    808[0m [38;5;28;01mif[39;00m recurse:
[1;32m    809[0m     [38;5;28;01mfor[39;00m module [38;5;129;01min[39;00m [38;5;28mself[39m[38;5;241m.[39mchildren():
[0;32m--> 810[0m         module[38;5;241m.[39m_apply(fn)
[1;32m    812[0m [38;5;28;01mdef[39;00m [38;5;21mcompute_should_use_set_data[39m(tensor, tensor_applied):
[1;32m    813[0m     [38;5;28;01mif[39;00m torch[38;5;241m.[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):
[1;32m    814[0m         [38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,[39;00m
[1;32m    815[0m         [38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,[39;00m
[0;32m   (...)[0m
[1;32m    820[0m         [38;5;66;03m# global flag to let the user control whether they want the future[39;00m
[1;32m    821[0m         [38;5;66;03m# behavior of overwriting the existing tensor or not.[39;00m

File [0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:833[0m, in [0;36mModule._apply[0;34m(self, fn, recurse)[0m
[1;32m    829[0m [38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to[39;00m
[1;32m    830[0m [38;5;66;03m# track autograd history of `param_applied`, so we have to use[39;00m
[1;32m    831[0m [38;5;66;03m# `with torch.no_grad():`[39;00m
[1;32m    832[0m [38;5;28;01mwith[39;00m torch[38;5;241m.[39mno_grad():
[0;32m--> 833[0m     param_applied [38;5;241m=[39m fn(param)
[1;32m    834[0m should_use_set_data [38;5;241m=[39m compute_should_use_set_data(param, param_applied)
[1;32m    835[0m [38;5;28;01mif[39;00m should_use_set_data:

File [0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1158[0m, in [0;36mModule.to.<locals>.convert[0;34m(t)[0m
[1;32m   1155[0m [38;5;28;01mif[39;00m convert_to_format [38;5;129;01mis[39;00m [38;5;129;01mnot[39;00m [38;5;28;01mNone[39;00m [38;5;129;01mand[39;00m t[38;5;241m.[39mdim() [38;5;129;01min[39;00m ([38;5;241m4[39m, [38;5;241m5[39m):
[1;32m   1156[0m     [38;5;28;01mreturn[39;00m t[38;5;241m.[39mto(device, dtype [38;5;28;01mif[39;00m t[38;5;241m.[39mis_floating_point() [38;5;129;01mor[39;00m t[38;5;241m.[39mis_complex() [38;5;28;01melse[39;00m [38;5;28;01mNone[39;00m,
[1;32m   1157[0m                 non_blocking, memory_format[38;5;241m=[39mconvert_to_format)
[0;32m-> 1158[0m [38;5;28;01mreturn[39;00m t[38;5;241m.[39mto(device, dtype [38;5;28;01mif[39;00m t[38;5;241m.[39mis_floating_point() [38;5;129;01mor[39;00m t[38;5;241m.[39mis_complex() [38;5;28;01melse[39;00m [38;5;28;01mNone[39;00m, non_blocking)

File [0;32m~/anaconda3/lib/python3.11/site-packages/torch/cuda/__init__.py:289[0m, in [0;36m_lazy_init[0;34m()[0m
[1;32m    284[0m     [38;5;28;01mraise[39;00m [38;5;167;01mRuntimeError[39;00m(
[1;32m    285[0m         [38;5;124m"[39m[38;5;124mCannot re-initialize CUDA in forked subprocess. To use CUDA with [39m[38;5;124m"[39m
[1;32m    286[0m         [38;5;124m"[39m[38;5;124mmultiprocessing, you must use the [39m[38;5;124m'[39m[38;5;124mspawn[39m[38;5;124m'[39m[38;5;124m start method[39m[38;5;124m"[39m
[1;32m    287[0m     )
[1;32m    288[0m [38;5;28;01mif[39;00m [38;5;129;01mnot[39;00m [38;5;28mhasattr[39m(torch[38;5;241m.[39m_C, [38;5;124m"[39m[38;5;124m_cuda_getDeviceCount[39m[38;5;124m"[39m):
[0;32m--> 289[0m     [38;5;28;01mraise[39;00m [38;5;167;01mAssertionError[39;00m([38;5;124m"[39m[38;5;124mTorch not compiled with CUDA enabled[39m[38;5;124m"[39m)
[1;32m    290[0m [38;5;28;01mif[39;00m _cudart [38;5;129;01mis[39;00m [38;5;28;01mNone[39;00m:
[1;32m    291[0m     [38;5;28;01mraise[39;00m [38;5;167;01mAssertionError[39;00m(
[1;32m    292[0m         [38;5;124m"[39m[38;5;124mlibcudart functions unavailable. It looks like you have a broken build?[39m[38;5;124m"[39m
[1;32m    293[0m     )

[0;31mAssertionError[0m: Torch not compiled with CUDA enabled
AssertionError: Torch not compiled with CUDA enabled

